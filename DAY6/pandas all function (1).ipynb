{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to this Kernel\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='table_of_contents'></a>\n",
    "# Table of contents\n",
    "\n",
    "[1. How to import pandas and check the version?](#q1)\n",
    "\n",
    "[2. How to create a series from a list, numpy array and dict?](#q2)\n",
    "\n",
    "[3. How to convert the index of a series into a column of a dataframe?](#q3)\n",
    "\n",
    "[4. How to combine many series to form a dataframe?](#q4)\n",
    "\n",
    "[5. How to assign name to the series’ index?](#q5)\n",
    "\n",
    "[6. How to get the items of series A not present in series B?](#q6)\n",
    "\n",
    "[7. How to get the items not common to both series A and series B?](#q7)\n",
    "\n",
    "[8. How to get the minimum, 25th percentile, median, 75th, and max of a numeric series?](#q8)\n",
    "\n",
    "[9. How to get frequency counts of unique items of a series?](#q9)\n",
    "\n",
    "[10. How to keep only top 2 most frequent values as it is and replace everything else as ‘Other’?](#q10)\n",
    "\n",
    "[11. How to bin a numeric series to 10 groups of equal size?](#q11)\n",
    "\n",
    "[12. How to convert a numpy array to a dataframe of given shape?](#q12)\n",
    "\n",
    "[13. How to find the positions of numbers that are multiples of 3 from a series?](#q13)\n",
    "\n",
    "[14. How to extract items at given positions from a series?](#q14)\n",
    "\n",
    "[15. How to stack two series vertically and horizontally ?](#q15)\n",
    "\n",
    "[16. How to get the positions of items of series A in another series B?](#q16)\n",
    "\n",
    "[17. How to compute the mean squared error on a truth and predicted series?](#q17)\n",
    "\n",
    "[18. How to convert the first character of each element in a series to uppercase?](#q18)\n",
    "\n",
    "[19. How to calculate the number of characters in each word in a series?](#q19)\n",
    "\n",
    "[20. How to compute difference of differences between consequtive numbers of a series?](#q20)\n",
    "\n",
    "[21. How to convert a series of date-strings to a timeseries?](#q21)\n",
    "\n",
    "[22. How to get the day of month, week number, day of year and day of week from a series of date strings?](#q22)\n",
    "\n",
    "[23. How to convert year-month string to dates corresponding to the 4th day of the month?](#q23)\n",
    "\n",
    "[24. How to filter words that contain atleast 2 vowels from a series?](#q24)\n",
    "\n",
    "[25. How to filter valid emails from a series?](#q25)\n",
    "\n",
    "[26. How to get the mean of a series grouped by another series?](#q26)\n",
    "\n",
    "[27. How to compute the euclidean distance between two series?](#q27)\n",
    "\n",
    "[28. How to find all the local maxima (or peaks) in a numeric series?](#q28)\n",
    "\n",
    "[29. How to replace missing spaces in a string with the least frequent character?](#q29)\n",
    "\n",
    "[30. How to create a TimeSeries starting ‘2000-01-01’ and 10 weekends (saturdays) after that having random numbers as values?](#q30)\n",
    "\n",
    "[31. How to fill an intermittent time series so all missing dates show up with values of previous non-missing date?](#q31)\n",
    "\n",
    "[32. How to compute the autocorrelations of a numeric series?](#q32)\n",
    "\n",
    "[33. How to import only every nth row from a csv file to create a dataframe?](#q33)\n",
    "\n",
    "[34. How to change column values when importing csv to a dataframe?](#q34)\n",
    "\n",
    "[35. How to create a dataframe with rows as strides from a given series?](#q35)\n",
    "\n",
    "[36. How to import only specified columns from a csv file?](#q36)\n",
    "\n",
    "[37. How to get the nrows, ncolumns, datatype, summary stats of each column of a dataframe? Also get the array and list equivalent.](#q37)\n",
    "\n",
    "[38. How to extract the row and column number of a particular cell with given criterion?](#q38)\n",
    "\n",
    "[39. How to rename a specific columns in a dataframe?](#q39)\n",
    "\n",
    "[40. How to check if a dataframe has any missing values?](#q40)\n",
    "\n",
    "[41. How to count the number of missing values in each column?](#q41)\n",
    "\n",
    "[42. How to replace missing values of multiple numeric columns with the mean?](#q42)\n",
    "\n",
    "[43. How to use apply function on existing columns with global variables as additional arguments?](#q43)\n",
    "\n",
    "[44. How to select a specific column from a dataframe as a dataframe instead of a series?](#q44)\n",
    "\n",
    "[45. How to change the order of columns of a dataframe?](#q45)\n",
    "\n",
    "[46. How to set the number of rows and columns displayed in the output?](#q46)\n",
    "\n",
    "[47. How to format or suppress scientific notations in a pandas dataframe?](#q47)\n",
    "\n",
    "[48. How to format all the values in a dataframe as percentages?](#q48)\n",
    "\n",
    "[49. How to filter every nth row in a dataframe?](#q49)\n",
    "\n",
    "[50. How to create a primary key index by combining relevant columns?](#q50)\n",
    "\n",
    "[51. How to get the row number of the nth largest value in a column?](#q51)\n",
    "\n",
    "[52. How to find the position of the nth largest value greater than a given value?](#q52)\n",
    "\n",
    "[53. How to get the last n rows of a dataframe with row sum > 100?](#q53)\n",
    "\n",
    "[54. How to find and cap outliers from a series or dataframe column?](#q54)\n",
    "\n",
    "[55. How to reshape a dataframe to the largest possible square after removing the negative values?](#q55)\n",
    "\n",
    "[56. How to swap two rows of a dataframe?](#q56)\n",
    "\n",
    "[57. How to reverse the rows of a dataframe?](#q57)\n",
    "\n",
    "[58. How to create one-hot encodings of a categorical variable (dummy variables)?](#q58)\n",
    "\n",
    "[59. Which column contains the highest number of row-wise maximum values?](#q59)\n",
    "\n",
    "[60. How to create a new column that contains the row number of nearest column by euclidean distance?](#q60)\n",
    "\n",
    "[61. How to know the maximum possible correlation value of each column against other columns?](#q61)\n",
    "\n",
    "[62. How to create a column containing the minimum by maximum of each row?](#q62)\n",
    "\n",
    "[63. How to create a column that contains the penultimate value in each row?](#q63)\n",
    "\n",
    "[64. How to normalize all columns in a dataframe?](#q64)\n",
    "\n",
    "[65. How to compute the correlation of each row with the suceeding row?](#q65)\n",
    "\n",
    "[66. How to replace both the diagonals of dataframe with 0?](#q66)\n",
    "\n",
    "[67. How to get the particular group of a groupby dataframe by key?](#q67)\n",
    "\n",
    "[68. How to get the n’th largest value of a column when grouped by another column?](#q68)\n",
    "\n",
    "[69. How to compute grouped mean on pandas dataframe and keep the grouped column as another column (not index)?](#q69)\n",
    "\n",
    "[70. How to join two dataframes by 2 columns so they have only the common rows?](#q70)\n",
    "\n",
    "[71. How to remove rows from a dataframe that are present in another dataframe?](#q71)\n",
    "\n",
    "[72. How to get the positions where values of two columns match?](#q72)\n",
    "\n",
    "[73. How to create lags and leads of a column in a dataframe?](#q73)\n",
    "\n",
    "[74. How to get the frequency of unique values in the entire dataframe?](#q74)\n",
    "\n",
    "[75. How to split a text column into two separate columns?](#q75)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# Allow several prints in one cell\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='q1'></a>\n",
    "**1. How to import pandas and check the version?**\n",
    "\n",
    "[Go back to the table of contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.3\n",
      "{\n",
      "  \"system\": {\n",
      "    \"commit\": \"0f437949513225922d851e9581723d82120684a6\",\n",
      "    \"python\": \"3.8.10.final.0\",\n",
      "    \"python-bits\": 64,\n",
      "    \"OS\": \"Windows\",\n",
      "    \"OS-release\": \"10\",\n",
      "    \"Version\": \"10.0.22631\",\n",
      "    \"machine\": \"AMD64\",\n",
      "    \"processor\": \"Intel64 Family 6 Model 186 Stepping 2, GenuineIntel\",\n",
      "    \"byteorder\": \"little\",\n",
      "    \"LC_ALL\": null,\n",
      "    \"LANG\": null,\n",
      "    \"LOCALE\": {\n",
      "      \"language-code\": \"English_United States\",\n",
      "      \"encoding\": \"1252\"\n",
      "    }\n",
      "  },\n",
      "  \"dependencies\": {\n",
      "    \"pandas\": \"2.0.3\",\n",
      "    \"numpy\": \"1.24.4\",\n",
      "    \"pytz\": \"2024.1\",\n",
      "    \"dateutil\": \"2.9.0.post0\",\n",
      "    \"setuptools\": \"56.0.0\",\n",
      "    \"pip\": \"21.1.1\",\n",
      "    \"Cython\": null,\n",
      "    \"pytest\": null,\n",
      "    \"hypothesis\": null,\n",
      "    \"sphinx\": null,\n",
      "    \"blosc\": null,\n",
      "    \"feather\": null,\n",
      "    \"xlsxwriter\": null,\n",
      "    \"lxml.etree\": null,\n",
      "    \"html5lib\": null,\n",
      "    \"pymysql\": null,\n",
      "    \"psycopg2\": null,\n",
      "    \"jinja2\": \"3.1.4\",\n",
      "    \"IPython\": \"8.12.3\",\n",
      "    \"pandas_datareader\": null,\n",
      "    \"bs4\": \"4.12.3\",\n",
      "    \"bottleneck\": null,\n",
      "    \"brotli\": null,\n",
      "    \"fastparquet\": null,\n",
      "    \"fsspec\": null,\n",
      "    \"gcsfs\": null,\n",
      "    \"matplotlib\": null,\n",
      "    \"numba\": null,\n",
      "    \"numexpr\": null,\n",
      "    \"odfpy\": null,\n",
      "    \"openpyxl\": null,\n",
      "    \"pandas_gbq\": null,\n",
      "    \"pyarrow\": null,\n",
      "    \"pyreadstat\": null,\n",
      "    \"pyxlsb\": null,\n",
      "    \"s3fs\": null,\n",
      "    \"scipy\": null,\n",
      "    \"snappy\": null,\n",
      "    \"sqlalchemy\": null,\n",
      "    \"tables\": null,\n",
      "    \"tabulate\": null,\n",
      "    \"xarray\": null,\n",
      "    \"xlrd\": null,\n",
      "    \"zstandard\": null,\n",
      "    \"tzdata\": \"2024.1\",\n",
      "    \"qtpy\": null,\n",
      "    \"pyqt5\": null\n",
      "  }\n",
      "}None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print(pd.__version__)\n",
    "\n",
    "# Print all pandas dependencies\n",
    "print(pd.show_versions(as_json=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'q2'></a>\n",
    "\n",
    "**2. How to create a series from a list, numpy array and dict?**\n",
    "\n",
    "Create a pandas series from each of the items below: a list, numpy and a dictionary\n",
    "\n",
    "[Go back to the table of contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b', 'c', 'd', 'e', 'f', 'g']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "import numpy as np\n",
    "a_list = list(\"abcdefg\")\n",
    "numpy_array = np.arange(1, 10)\n",
    "dictionary = {\"A\":  0, \"B\":1, \"C\":2, \"D\":3, \"E\":5}\n",
    "a_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    a\n",
      "1    b\n",
      "2    c\n",
      "3    d\n",
      "4    e\n",
      "5    f\n",
      "6    g\n",
      "dtype: object\n",
      "0    1\n",
      "1    2\n",
      "2    3\n",
      "3    4\n",
      "4    5\n",
      "5    6\n",
      "6    7\n",
      "7    8\n",
      "8    9\n",
      "dtype: int32\n",
      "A    0\n",
      "B    1\n",
      "C    2\n",
      "D    3\n",
      "E    5\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "series1 = pd.Series(a_list)\n",
    "print(series1)\n",
    "series2 = pd.Series(numpy_array)\n",
    "print(series2)\n",
    "series3 = pd.Series(dictionary)\n",
    "print(series3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'q3'></a>\n",
    "**3. How to convert the index of a series into a column of a dataframe?**\n",
    "\n",
    "Convert the series ser into a dataframe with its index as another column on the dataframe.\n",
    "\n",
    "[Go back to the table of contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    0\n",
      "b    1\n",
      "c    2\n",
      "e    3\n",
      "d    4\n",
      "dtype: int32\n"
     ]
    }
   ],
   "source": [
    "# input\n",
    "mylist = list('abcedfghijklmnopqrstuvwxyz')\n",
    "myarr = np.arange(26)\n",
    "mydict = dict(zip(mylist, myarr))\n",
    "ser = pd.Series(mydict)\n",
    "print(ser[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>f</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>g</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>h</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>i</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>j</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>k</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>l</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>m</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>n</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>o</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>p</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>q</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>r</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>s</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>t</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>u</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>v</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>w</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>x</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>y</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>z</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index   0\n",
       "0      a   0\n",
       "1      b   1\n",
       "2      c   2\n",
       "3      e   3\n",
       "4      d   4\n",
       "5      f   5\n",
       "6      g   6\n",
       "7      h   7\n",
       "8      i   8\n",
       "9      j   9\n",
       "10     k  10\n",
       "11     l  11\n",
       "12     m  12\n",
       "13     n  13\n",
       "14     o  14\n",
       "15     p  15\n",
       "16     q  16\n",
       "17     r  17\n",
       "18     s  18\n",
       "19     t  19\n",
       "20     u  20\n",
       "21     v  21\n",
       "22     w  22\n",
       "23     x  23\n",
       "24     y  24\n",
       "25     z  25"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>f</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>g</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>h</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>i</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>j</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>k</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>l</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>m</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>n</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>o</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>p</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>q</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>r</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>s</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>t</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>u</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>v</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>w</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>x</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>y</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>z</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index   0\n",
       "0      a   0\n",
       "1      b   1\n",
       "2      c   2\n",
       "3      e   3\n",
       "4      d   4\n",
       "5      f   5\n",
       "6      g   6\n",
       "7      h   7\n",
       "8      i   8\n",
       "9      j   9\n",
       "10     k  10\n",
       "11     l  11\n",
       "12     m  12\n",
       "13     n  13\n",
       "14     o  14\n",
       "15     p  15\n",
       "16     q  16\n",
       "17     r  17\n",
       "18     s  18\n",
       "19     t  19\n",
       "20     u  20\n",
       "21     v  21\n",
       "22     w  22\n",
       "23     x  23\n",
       "24     y  24\n",
       "25     z  25"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# solution 1 using DataFrame\n",
    "ser_df = pd.DataFrame(ser)\n",
    "ser_df.reset_index()\n",
    "\n",
    "# using pandas to_frame()\n",
    "ser_df = ser.to_frame().reset_index()\n",
    "ser_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'q4'></a>\n",
    "**4. How to combine many series to form a dataframe?**\n",
    "\n",
    "Combine ser1 and ser2 to form a dataframe.\n",
    "\n",
    "[Go back to the table of contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "ser1 = pd.Series(list('abcedfghijklmnopqrstuvwxyz'))\n",
    "ser2 = pd.Series(np.arange(26))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  0\n",
       "0      0  a\n",
       "1      1  b\n",
       "2      2  c\n",
       "3      3  e\n",
       "4      4  d"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  col1  col2\n",
       "0    a     0\n",
       "1    b     1\n",
       "2    c     2\n",
       "3    e     3\n",
       "4    d     4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1\n",
       "0  a  0\n",
       "1  b  1\n",
       "2  c  2\n",
       "3  e  3\n",
       "4  d  4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using pandas DataFrame\n",
    "ser_df = pd.DataFrame(ser1, ser2).reset_index()\n",
    "ser_df.head()\n",
    "# using pandas DataFrame with a dictionary, gives a specific name to the column\n",
    "ser_df = pd.DataFrame({\"col1\":ser1, \"col2\":ser2})\n",
    "ser_df.head(5)\n",
    "# using pandas concat\n",
    "ser_df = pd.concat([ser1, ser2], axis = 1)\n",
    "ser_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'q5'></a>\n",
    "**5. How to assign name to the series’ index?**\n",
    "\n",
    "Give a name to the series ser calling it ‘alphabets’.\n",
    "\n",
    "[Go back to the table of contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "ser = pd.Series(list('abcedfghijklmnopqrstuvwxyz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     a\n",
       "1     b\n",
       "2     c\n",
       "3     e\n",
       "4     d\n",
       "5     f\n",
       "6     g\n",
       "7     h\n",
       "8     i\n",
       "9     j\n",
       "10    k\n",
       "11    l\n",
       "12    m\n",
       "13    n\n",
       "14    o\n",
       "15    p\n",
       "16    q\n",
       "17    r\n",
       "18    s\n",
       "19    t\n",
       "20    u\n",
       "21    v\n",
       "22    w\n",
       "23    x\n",
       "24    y\n",
       "25    z\n",
       "Name: alphabets, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0     a\n",
       "1     b\n",
       "2     c\n",
       "3     e\n",
       "4     d\n",
       "5     f\n",
       "6     g\n",
       "7     h\n",
       "8     i\n",
       "9     j\n",
       "10    k\n",
       "11    l\n",
       "12    m\n",
       "13    n\n",
       "14    o\n",
       "15    p\n",
       "16    q\n",
       "17    r\n",
       "18    s\n",
       "19    t\n",
       "20    u\n",
       "21    v\n",
       "22    w\n",
       "23    x\n",
       "24    y\n",
       "25    z\n",
       "Name: other_name, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using series rename method\n",
    "ser.rename(\"alphabets\")\n",
    "# using series attribute\n",
    "ser.name = \"other_name\"\n",
    "ser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'q6'></a>\n",
    "**6. How to get the items of series A not present in series B?**\n",
    "\n",
    "Get all items of ser1 and ser2 not common to both.\n",
    "\n",
    "[Go back to the table of contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "ser1 = pd.Series([1, 2, 3, 4, 5])\n",
    "ser2 = pd.Series([4, 5, 6, 7, 8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "2    3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser1[~ser1.isin(ser2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'q7'></a>\n",
    "**7. How to get the items not common to both series A and series B?**\n",
    "\n",
    "Get all items of ser1 and ser2 not common to both.\n",
    "\n",
    "[Go back to the table of contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "ser1 = pd.Series([1, 2, 3, 4, 5])\n",
    "ser2 = pd.Series([4, 5, 6, 7, 8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "2    3\n",
       "5    6\n",
       "6    7\n",
       "7    8\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using pandas\n",
    "a_not_b = ser1[~ser1.isin(ser2)]\n",
    "b_not_a = ser2[~ser2.isin(ser1)]\n",
    "                          \n",
    "# a_not_b.append(b_not_a, ignore_index = True)\n",
    "\n",
    "result = pd.concat([a_not_b, b_not_a], ignore_index=True)\n",
    "# using numpy union and intersection\n",
    "ser_u = pd.Series(np.union1d(ser1, ser2))\n",
    "ser_i = pd.Series(np.intersect1d(ser1, ser2))\n",
    "ser_u[~ser_u.isin(ser_i)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'q8'></a>\n",
    "**8. How to get the minimum, 25th percentile, median, 75th, and max of a numeric series?**\n",
    "\n",
    "Compute the minimum, 25th percentile, median, 75th, and maximum of ser.\n",
    "\n",
    "[Go back to the table of contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "state = np.random.RandomState(100)\n",
    "ser = pd.Series(state.normal(10, 5, 25))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    25.000000\n",
       "mean     10.435437\n",
       "std       4.253118\n",
       "min       1.251173\n",
       "25%       7.709865\n",
       "50%      10.922593\n",
       "75%      13.363604\n",
       "max      18.094908\n",
       "dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([ 1.25117263,  7.70986507, 10.92259345, 13.36360403, 18.0949083 ])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using pandas\n",
    "ser.describe()\n",
    "\n",
    "# or using numpy\n",
    "np.percentile(ser, q = [0, 25, 50, 75, 100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'q9'></a>\n",
    "**9. How to get frequency counts of unique items of a series?**\n",
    "\n",
    "Calculate the frequency counts of each unique value ser.\n",
    "\n",
    "[Go back to the table of contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "ser = pd.Series(np.take(list('abcdefgh'), np.random.randint(8, size=30)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "c    5\n",
       "e    5\n",
       "a    4\n",
       "b    4\n",
       "h    4\n",
       "d    3\n",
       "f    3\n",
       "g    2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'q10'></a>\n",
    "**10. How to keep only top 2 most frequent values as it is and replace everything else as ‘Other’?**\n",
    "\n",
    "From ser, keep the top 2 most frequent items as it is and replace everything else as ‘Other’.\n",
    "\n",
    "[Go back to the table of contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomState(MT19937) at 0x2A53E54A440"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0     1\n",
       "1     4\n",
       "2     1\n",
       "3     2\n",
       "4     4\n",
       "5     1\n",
       "6     1\n",
       "7     3\n",
       "8     1\n",
       "9     2\n",
       "10    3\n",
       "11    2\n",
       "dtype: int32"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input\n",
    "np.random.RandomState(100)\n",
    "ser = pd.Series(np.random.randint(1, 5, [12]))\n",
    "ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    5\n",
       "2    3\n",
       "4    2\n",
       "3    2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0         1\n",
       "1     Other\n",
       "2         1\n",
       "3         2\n",
       "4     Other\n",
       "5         1\n",
       "6         1\n",
       "7     Other\n",
       "8         1\n",
       "9         2\n",
       "10    Other\n",
       "11        2\n",
       "dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser.value_counts()\n",
    "ser[~ser.isin(ser.value_counts().index[:2])] = 'Other'\n",
    "ser\n",
    "# we do value_counts to see the repetitions for each value, then we do ~ser.isin value_counts, filter by index the first 2 and = \"Other renames the values\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'q11'></a>\n",
    "**11. How to bin a numeric series to 10 groups of equal size?**\n",
    "\n",
    "Bin the series ser into 10 equal deciles and replace the values with the bin name.\n",
    "\n",
    "[Go back to the table of contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0.128352\n",
       "1     0.947435\n",
       "2     0.258186\n",
       "3     0.990311\n",
       "4     0.659083\n",
       "5     0.388860\n",
       "6     0.667310\n",
       "7     0.294516\n",
       "8     0.623888\n",
       "9     0.397457\n",
       "10    0.075829\n",
       "11    0.552003\n",
       "12    0.011219\n",
       "13    0.598693\n",
       "14    0.283636\n",
       "15    0.169219\n",
       "16    0.735377\n",
       "17    0.229161\n",
       "18    0.904433\n",
       "19    0.443603\n",
       "dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input\n",
    "ser = pd.Series(np.random.random(20))\n",
    "ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.qcut(ser, q = 10)\n",
    "# we can also pass labels\n",
    "pd.qcut(ser, q = [0, .10, .20, .30, .40, .50, .60, .70, .80, .90, 1], labels=['1st', '2nd', '3rd', '4th', '5th', '6th', '7th', '8th', '9th', '10th']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'q12'></a>\n",
    "**12. How to convert a numpy array to a dataframe of given shape? (L1)**\n",
    "\n",
    "Reshape the series ser into a dataframe with 7 rows and 5 columns\n",
    "\n",
    "[Go back to the table of contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "ser = pd.Series(np.random.randint(1, 10, 35))\n",
    "ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using numpy\n",
    "pd.DataFrame(np.array(ser).reshape(7, 5))\n",
    "\n",
    "# using only pandas\n",
    "pd.DataFrame(ser.values.reshape(7, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'q13'></a>\n",
    "**13. How to find the positions of numbers that are multiples of 3 from a series?**\n",
    "\n",
    "Find the positions of numbers that are multiples of 3 from ser.\n",
    "\n",
    "[Go back to the table of contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "\n",
    "np.random.RandomState(100)\n",
    "ser = pd.Series(np.random.randint(1, 5, 10))\n",
    "ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the where clause\n",
    "ser.where(lambda x: x%3 == 0).dropna()\n",
    "\n",
    "# using numpy and reshape to get a pandas series\n",
    "#pd.Series(np.argwhere(ser%3 == 0).reshape(4))\n",
    "np.argwhere(ser%3 == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'q14'></a>\n",
    "**14. How to extract items at given positions from a series**\n",
    "\n",
    "From ser, extract the items at positions in list pos.\n",
    "\n",
    "[Go back to the table of contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "\n",
    "ser = pd.Series(list('abcdefghijklmnopqrstuvwxyz'))\n",
    "pos = [0, 4, 8, 14, 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using loc\n",
    "ser.loc[pos]\n",
    "\n",
    "# using series take\n",
    "ser.take(pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'q15'></a>\n",
    "\n",
    "**15. How to stack two series vertically and horizontally ?**\n",
    "\n",
    "Stack ser1 and ser2 vertically and horizontally (to form a dataframe).\n",
    "\n",
    "[Go back to the table of contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "ser1 = pd.Series(range(5))\n",
    "ser2 = pd.Series(list('abcde'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vertical\n",
    "ser1.append(ser2)\n",
    "# or using pandas concat and axis = 0\n",
    "pd.concat([ser1, ser2], axis = 0)\n",
    "\n",
    "# horizontal\n",
    "pd.concat([ser1, ser2], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'q16'></a>\n",
    "**16. How to get the positions of items of series A in another series B?**\n",
    "\n",
    "Get the positions of items of ser2 in ser1 as a list.\n",
    "\n",
    "[Go back to the table of contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "ser1 = pd.Series([10, 9, 6, 5, 3, 1, 12, 8, 13])\n",
    "ser2 = pd.Series([1, 3, 10, 13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get's the index, but it's sorts the index\n",
    "list(ser1[ser1.isin(ser2)].index)\n",
    "\n",
    "# using numpy where\n",
    "[np.where(i == ser1)[0].tolist()[0] for i in ser2]\n",
    "\n",
    "# using pandas Index and get location\n",
    "[pd.Index(ser1).get_loc(i) for i in ser2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'q17'></a>\n",
    "**17. How to compute the mean squared error on a truth and predicted series?**\n",
    "\n",
    "Compute the mean squared error of truth and pred series.\n",
    "\n",
    "[Go back to the table of contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "truth = pd.Series(range(10))\n",
    "pred = pd.Series(range(10)) + np.random.random(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BAD, don't use it\n",
    "(np.mean([(truth_i - pred_i)**2 for truth_i, pred_i in zip(truth, pred)]))\n",
    "\n",
    "# using numpy\n",
    "np.mean((truth-pred)**2)\n",
    "\n",
    "# using sklear metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(truth, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'q18'></a>\n",
    "\n",
    "**18. How to convert the first character of each element in a series to uppercase?**\n",
    "\n",
    "Change the first character of each word to upper case in each word of ser.\n",
    "\n",
    "[Go back to the table of contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "ser = pd.Series(['just', 'a', 'random', 'list'])\n",
    "ser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using python string method title() Assumes we only encounter string in the list\n",
    "[i.title() for i in ser]\n",
    "\n",
    "# using lambda\n",
    "ser.map(lambda x: x.title())\n",
    "\n",
    "# other solution\n",
    "ser.map(lambda x: x[0].upper() + x[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'q19'></a>\n",
    "\n",
    "**19. How to calculate the number of characters in each word in a series?**\n",
    "\n",
    "[Go back to the table of contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "ser = pd.Series(['just', 'a', 'random', 'list'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using list comprehension\n",
    "[len(i) for i in ser]\n",
    "\n",
    "# using series map\n",
    "ser.map(len)\n",
    "\n",
    "# using series apply\n",
    "ser.apply(len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'q20'></a>\n",
    "**20. How to compute difference of differences between consequtive numbers of a series?**\n",
    "\n",
    "Difference of differences between the consequtive numbers of ser.\n",
    "\n",
    "[Go back to the table of contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "ser = pd.Series([1, 3, 6, 10, 15, 21, 27, 35])\n",
    "\n",
    "# Desired Output\n",
    "# [nan, 2.0, 3.0, 4.0, 5.0, 6.0, 6.0, 8.0]\n",
    "# [nan, nan, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using pandas diff()\n",
    "ser.diff(periods = 1).tolist()\n",
    "ser.diff(periods = 1).diff(periods = 1).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'q21'></a>\n",
    "\n",
    "**21. How to convert a series of date-strings to a timeseries?**\n",
    "\n",
    "[Go back to the table of contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "ser = pd.Series(['01 Jan 2010', '02-02-2011', '20120303', '2013/04/04', '2014-05-05', '2015-06-06T12:20'])\n",
    "\n",
    "\n",
    "'''\n",
    "Desired Output\n",
    "\n",
    "0   2010-01-01 00:00:00\n",
    "1   2011-02-02 00:00:00\n",
    "2   2012-03-03 00:00:00\n",
    "3   2013-04-04 00:00:00\n",
    "4   2014-05-05 00:00:00\n",
    "5   2015-06-06 12:20:00\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using pands to_datetime\n",
    "pd.to_datetime(ser)\n",
    "\n",
    "# using dateutil parse\n",
    "from dateutil.parser import parse\n",
    "ser.map(lambda x: parse(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'q22'></a>\n",
    "**22. How to get the day of month, week number, day of year and day of week from a series of date strings?**\n",
    "\n",
    "Get the day of month, week number, day of year and day of week from ser.\n",
    "\n",
    "[Go back to the table of contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "ser = pd.Series(['01 Jan 2010', '02-02-2011', '20120303', '2013/04/04', '2014-05-05', '2015-06-06T12:20'])\n",
    "\n",
    "'''\n",
    "Desired output\n",
    "\n",
    "Date:  [1, 2, 3, 4, 5, 6]\n",
    "Week number:  [53, 5, 9, 14, 19, 23]\n",
    "Day num of year:  [1, 33, 63, 94, 125, 157]\n",
    "Day of week:  ['Friday', 'Wednesday', 'Saturday', 'Thursday', 'Monday', 'Saturday']\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# day\n",
    "pd.to_datetime(ser).dt.day.to_list()\n",
    "# week\n",
    "pd.to_datetime(ser).dt.week.to_list()\n",
    "# another method\n",
    "pd.to_datetime(ser).dt.weekofyear.to_list()\n",
    "# day of year\n",
    "pd.to_datetime(ser).dt.dayofyear.to_list()\n",
    "# day of week in words\n",
    "week_dict = {0:\"Monday\", 1:\"Tuesday\", 2:\"Wednesday\", 3:\"Thursday\", 4:\"Friday\", 5:\"Saturday\", 6:\"Sunday\"}\n",
    "pd.to_datetime(ser).dt.dayofweek.map(week_dict).to_list()\n",
    "# another method\n",
    "pd.to_datetime(ser).dt.weekday_name.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'q23'></a>\n",
    "\n",
    "**23. How to convert year-month string to dates corresponding to the 4th day of the month?**\n",
    "\n",
    "Change ser to dates that start with 4th of the respective months.\n",
    "\n",
    "[Go back to the table of contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "ser = pd.Series(['Jan 2010', 'Feb 2011', 'Mar 2012'])\n",
    "\n",
    "'''\n",
    "Desired Output\n",
    "\n",
    "0   2010-01-04\n",
    "1   2011-02-04\n",
    "2   2012-03-04\n",
    "dtype: datetime64[ns]\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution using parser\n",
    "from dateutil.parser import parse\n",
    "ser.map(lambda x: parse('04 ' + x))\n",
    "\n",
    "# another solution\n",
    "\n",
    "from dateutil.parser import parse\n",
    "# Parse the date\n",
    "ser_ts = ser.map(lambda x: parse(x))\n",
    "\n",
    "# Construct date string with date as 4\n",
    "ser_datestr = ser_ts.dt.year.astype('str') + '-' + ser_ts.dt.month.astype('str') + '-' + '04'\n",
    "\n",
    "# Format it.\n",
    "[parse(i).strftime('%Y-%m-%d') for i in ser_datestr]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'q24'></a>\n",
    "\n",
    "**24. How to filter words that contain atleast 2 vowels from a series?**\n",
    "\n",
    "From ser, extract words that contain atleast 2 vowels.\n",
    "\n",
    "[Go back to the table of contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "ser = pd.Series(['Apple', 'Orange', 'Plan', 'Python', 'Money'])\n",
    "\n",
    "'''\n",
    "Desired Output\n",
    "\n",
    "\n",
    "0     Apple\n",
    "1    Orange\n",
    "4     Money\n",
    "dtype: object\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using nested loops\n",
    "vowels = list(\"aeiou\")\n",
    "list_ = []\n",
    "for w in ser:\n",
    "    c = 0\n",
    "    for l in list(w.lower()):\n",
    "        if l in vowels:\n",
    "            c += 1\n",
    "    if c >= 2:\n",
    "        print(w)\n",
    "        list_.append(w)\n",
    "\n",
    "ser[ser.isin(list_)]\n",
    "\n",
    "# another solution using counter\n",
    "\n",
    "from collections import Counter\n",
    "mask = ser.map(lambda x: sum([Counter(x.lower()).get(i, 0) for i in list('aeiou')]) >= 2)\n",
    "ser[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'q25'></a>\n",
    "\n",
    "**25. How to filter valid emails from a series?**\n",
    "\n",
    "Extract the valid emails from the series emails. The regex pattern for valid emails is provided as reference.\n",
    "\n",
    "[Go back to the table of contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "emails = pd.Series(['buying books at amazom.com', 'rameses@egypt.com', 'matt@t.co', 'narendra@modi.com'])\n",
    "pattern ='[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\\\.[A-Za-z]{2,4}'\n",
    "\n",
    "'''\n",
    "Desired Output\n",
    "\n",
    "1    rameses@egypt.com\n",
    "2            matt@t.co\n",
    "3    narendra@modi.com\n",
    "dtype: object\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using powerful regex\n",
    "import re\n",
    "re_ = re.compile(pattern)\n",
    "emails[emails.str.contains(pat = re_, regex = True)]\n",
    "\n",
    "# other solutions\n",
    "pattern ='[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\\\.[A-Za-z]{2,4}'\n",
    "mask = emails.map(lambda x: bool(re.match(pattern, x)))\n",
    "emails[mask]\n",
    "\n",
    "# using str.findall\n",
    "emails.str.findall(pattern, flags=re.IGNORECASE)\n",
    "\n",
    "# using list comprehension\n",
    "[x[0] for x in [re.findall(pattern, email) for email in emails] if len(x) > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'q26'></a>\n",
    "\n",
    "**26. How to get the mean of a series grouped by another series?**\n",
    "\n",
    "Compute the mean of weights of each fruit.\n",
    "\n",
    "[Go back to the table of contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doesn't incluide the upper limit\n",
    "fruit = pd.Series(np.random.choice(['apple', 'banana', 'carrot'], 10))\n",
    "fruit\n",
    "weights = pd.Series(np.linspace(1, 10, 10))\n",
    "weights\n",
    "#print(weights.tolist())\n",
    "#print(fruit.tolist())\n",
    "\n",
    "'''\n",
    "Desired output\n",
    "\n",
    "# values can change due to randomness\n",
    "apple     6.0\n",
    "banana    4.0\n",
    "carrot    5.8\n",
    "dtype: float64\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using pandas groupby\n",
    "df = pd.concat([fruit, weights], axis = 1)\n",
    "df\n",
    "df.groupby(0).mean()\n",
    "\n",
    "# use one list to calculate a kpi from another\n",
    "weights.groupby(fruit).mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'q27'></a>\n",
    "\n",
    "**27. How to compute the euclidean distance between two series?**\n",
    "\n",
    "Compute the [euclidean distance](https://en.wikipedia.org/wiki/Euclidean_distance) between series (points) p and q, without using a packaged formula.\n",
    "\n",
    "[Go back to the table of contents](#table_of_contents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "p = pd.Series([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "q = pd.Series([10, 9, 8, 7, 6, 5, 4, 3, 2, 1])\n",
    "'''\n",
    "Desired Output\n",
    "\n",
    "18.165\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using list comprehension\n",
    "suma = np.sqrt(np.sum([(p - q)**2 for p, q in zip(p, q)]))\n",
    "suma\n",
    "\n",
    "# using series one to one operation\n",
    "sum((p - q)**2)**.5\n",
    "\n",
    "# using numpy\n",
    "np.linalg.norm(p-q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'q28'></a>\n",
    "\n",
    "**28. How to find all the local maxima (or peaks) in a numeric series?**\n",
    "\n",
    "[Go back to the table of contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "ser = pd.Series([2, 10, 3, 4, 9, 10, 2, 7, 3])\n",
    "\n",
    "'''\n",
    "Desired output\n",
    "\n",
    "array([1, 5, 7])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using pandas shift\n",
    "local_max = ser[(ser.shift(1) < ser) & (ser.shift(-1) < ser)]\n",
    "local_max.index\n",
    "\n",
    "# using numpy\n",
    "dd = np.diff(np.sign(np.diff(ser)))\n",
    "dd\n",
    "peak_locs = np.where(dd == -2)[0] + 1\n",
    "peak_locs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'q29'></a>\n",
    "\n",
    "**29. How to replace missing spaces in a string with the least frequent character?**\n",
    "\n",
    "Replace the spaces in my_str with the least frequent character.\n",
    "\n",
    "[Go back to the table of contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "my_str = 'dbc deb abed ggade'\n",
    "\n",
    "'''\n",
    "Desired Output\n",
    "\n",
    "'dbccdebcabedcggade'  # least frequent is 'c'\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Counter\n",
    "from collections import Counter\n",
    "my_str_ = my_str\n",
    "Counter_ = Counter(list(my_str_.replace(\" \", \"\")))\n",
    "Counter_\n",
    "minimum = min(Counter_, key = Counter_.get)\n",
    "\n",
    "print(my_str.replace(\" \", minimum))\n",
    "\n",
    "# using pandas\n",
    "ser = pd.Series(list(my_str.replace(\" \", \"\")))\n",
    "ser.value_counts()\n",
    "minimum = list(ser.value_counts().index)[-1]\n",
    "minimum\n",
    "print(my_str.replace(\" \", minimum))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'q30'></a>\n",
    "\n",
    "**30. How to create a TimeSeries starting ‘2000-01-01’ and 10 weekends (saturdays) after that having random numbers as values?**\n",
    "\n",
    "[Go back to the table of contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Desired Output\n",
    "values can be random\n",
    "\n",
    "2000-01-01    4\n",
    "2000-01-08    1\n",
    "2000-01-15    8\n",
    "2000-01-22    4\n",
    "2000-01-29    4\n",
    "2000-02-05    2\n",
    "2000-02-12    4\n",
    "2000-02-19    9\n",
    "2000-02-26    6\n",
    "2000-03-04    6\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dti = pd.Series(pd.date_range('2000-01-01', periods=10, freq='W-SAT'))\n",
    "random_num = pd.Series([np.random.randint(1, 10) for i in range(10)])\n",
    "\n",
    "\n",
    "df = pd.concat({\"Time\":dti, \"Numbers\":random_num}, axis = 1)\n",
    "df\n",
    "\n",
    "# for more about time series functionality \n",
    "# https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#timeseries-offset-aliases\n",
    "\n",
    "# another solution just using pandas Series\n",
    "ser = pd.Series(np.random.randint(1,10,10), pd.date_range('2000-01-01', periods=10, freq='W-SAT'))\n",
    "ser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'q31'></a>\n",
    "\n",
    "**31. How to fill an intermittent time series so all missing dates show up with values of previous non-missing date?**\n",
    "\n",
    "ser has missing dates and values. Make all missing dates appear and fill up with value from previous date.\n",
    "\n",
    "[Go back to the table of contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "ser = pd.Series([1,10,3,np.nan], index=pd.to_datetime(['2000-01-01', '2000-01-03', '2000-01-06', '2000-01-08']))\n",
    "\n",
    "'''\n",
    "Desired Output\n",
    "\n",
    "2000-01-01     1.0\n",
    "2000-01-02     1.0\n",
    "2000-01-03    10.0\n",
    "2000-01-04    10.0\n",
    "2000-01-05    10.0\n",
    "2000-01-06     3.0\n",
    "2000-01-07     3.0\n",
    "2000-01-08     NaN\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 1\n",
    "# first let's fill the missing dates\n",
    "indx = pd.date_range(\"2000-01-01\", \"2000-01-08\")\n",
    "# now let's reindex the series ser with the new index\n",
    "# we have to reasing back to ser\n",
    "ser = ser.reindex(indx)\n",
    "# lastly let's populate the missing values\n",
    "ser.fillna(method = \"ffill\")\n",
    "\n",
    "# Solution 2\n",
    "ser = pd.Series([1,10,3,np.nan], index=pd.to_datetime(['2000-01-01', '2000-01-03', '2000-01-06', '2000-01-08']))\n",
    "ser.resample('D').ffill()  # fill with previous value\n",
    "ser.resample('D').bfill()  # fill with next value\n",
    "ser.resample('D').bfill().ffill()  # fill next else prev value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'q32'></a>\n",
    "\n",
    "**32. How to compute the autocorrelations of a numeric series?**\n",
    "\n",
    "Compute autocorrelations for the first 10 lags of ser. Find out which lag has the largest correlation.\n",
    "\n",
    "[Go back to the table of contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "ser = pd.Series(np.arange(20) + np.random.normal(1, 10, 20))\n",
    "\n",
    "'''\n",
    "Desired Output\n",
    "\n",
    "# values will change due to randomness\n",
    "[0.29999999999999999, -0.11, -0.17000000000000001, 0.46000000000000002, 0.28000000000000003, -0.040000000000000001, -0.37, 0.41999999999999998, 0.47999999999999998, 0.17999999999999999]\n",
    "Lag having highest correlation:  9\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using pandas autocorr\n",
    "# ser.autocorr(lag = 10)\n",
    "\n",
    "# solution using list comprehension\n",
    "autocorrelations = [ser.autocorr(i).round(2) for i in range(11)]\n",
    "print(autocorrelations[1:])\n",
    "print('Lag having highest correlation: ', np.argmax(np.abs(autocorrelations[1:]))+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'q33'></a>\n",
    "\n",
    "**33. How to import only every nth row from a csv file to create a dataframe?**\n",
    "\n",
    "Import every 50th row of BostonHousing dataset as a dataframe.\n",
    "\n",
    "[Go back to the table of contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data comes without headers, but we searched for it\n",
    "names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
    "\n",
    "# pure Python implementation\n",
    "with open(\"/kaggle/input/boston-house-prices/housing.csv\") as f:\n",
    "    data = f.read()\n",
    "    nth_rows = []\n",
    "    for i, rows in enumerate(data.split(\"\\n\")):\n",
    "        if i%50 == 0:\n",
    "            nth_rows.append(rows)\n",
    "            \n",
    "# nth_rows is a list of strings separated by blank spaces \" \"\n",
    "# the next list comprehension will do the trick\n",
    "\n",
    "nth_rows[0]\n",
    "data_ = [nth_rows[i].split() for i in range(len(nth_rows))]\n",
    "df = pd.DataFrame(data_, columns=names)\n",
    "df\n",
    "\n",
    "# other solutions\n",
    "\n",
    "# Solution 2: Use chunks and for-loop\n",
    "# df = pd.read_csv(\"/kaggle/input/boston-house-prices/housing.csv\", chunksize=50)\n",
    "# df2 = pd.DataFrame()\n",
    "# for chunk in df:\n",
    "#     df2 = df2.append(chunk.iloc[0,:])\n",
    "# df2\n",
    "\n",
    "# Solution 3: Use chunks and list comprehension\n",
    "# df = pd.read_csv(\"/kaggle/input/boston-house-prices/housing.csv\", chunksize=50)\n",
    "# df2 = pd.concat([chunk.iloc[0] for chunk in df], axis=1)\n",
    "# df2 = df2.transpose()\n",
    "# df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'q34'></a>\n",
    "\n",
    "**34. How to change column values when importing csv to a dataframe?**\n",
    "\n",
    "Import the boston housing dataset, but while importing change the 'medv' (median house value) column so that values < 25 becomes ‘Low’ and > 25 becomes ‘High’.\n",
    "\n",
    "[Go back to the table of contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first let's import using the previuos code and save as a normal csv\n",
    "\n",
    "names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
    "with open(\"/kaggle/input/boston-house-prices/housing.csv\") as f:\n",
    "    data = f.read()\n",
    "    nth_rows = []\n",
    "    for i, rows in enumerate(data.split(\"\\n\")):\n",
    "        nth_rows.append(rows)\n",
    "\n",
    "data_ = [nth_rows[i].split() for i in range(len(nth_rows))]\n",
    "\n",
    "df = pd.DataFrame(data_, columns=names)\n",
    "df.head()\n",
    "df.to_csv(\"housing_preprocessed.csv\")\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's start importing as normal and use converters to convert the values\n",
    "# skipfooter because we had the last rows with nan values and index_col to specify that the first column is the index\n",
    "df = pd.read_csv(\"housing_preprocessed.csv\",  index_col = 0, skipfooter=1,  converters = {\"MEDV\": lambda x: \"HIGH\" if float(x) >= 25 else \"LOW\"})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'q35'></a>\n",
    "\n",
    "**35. How to create a dataframe with rows as strides from a given series?**\n",
    "\n",
    "[Go back to the table of contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "L = pd.Series(range(15))\n",
    "\n",
    "'''\n",
    "Desired Output\n",
    "\n",
    "array([[ 0,  1,  2,  3],\n",
    "       [ 2,  3,  4,  5],\n",
    "       [ 4,  5,  6,  7],\n",
    "       [ 6,  7,  8,  9],\n",
    "       [ 8,  9, 10, 11],\n",
    "       [10, 11, 12, 13]])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using slicing\n",
    "# let's generate a list of indexes we need to use\n",
    "# outputs array([ 0,  2,  4,  6,  8, 10, 12, 14])\n",
    "index_ = np.arange(0, 15, 2)\n",
    "index_\n",
    "my_list = []\n",
    "for i in range(6):\n",
    "    my_list.append(list(L[index_[i]:index_[i+2]]))\n",
    "np.array(my_list)\n",
    "\n",
    "# above code as list comprehension\n",
    "np.array([L[index_[i]:index_[i+2]] for i in range(6)])\n",
    "\n",
    "# another solution\n",
    "def gen_strides(a, stride_len=5, window_len=5):\n",
    "    n_strides = ((a.size-window_len)//stride_len) + 1\n",
    "    return np.array([a[s:(s+window_len)] for s in np.arange(0, a.size, stride_len)[:n_strides]])\n",
    "\n",
    "gen_strides(L, stride_len=2, window_len=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'q36'></a>\n",
    "\n",
    "**36. How to import only specified columns from a csv file?**\n",
    "\n",
    "[Go back to the table of contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "        \n",
    "# code that generates the housing_preprocessed.csv file\n",
    "names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
    "with open(\"/kaggle/input/boston-house-prices/housing.csv\") as f:\n",
    "    data = f.read()\n",
    "    nth_rows = []\n",
    "    for i, rows in enumerate(data.split(\"\\n\")):\n",
    "        nth_rows.append(rows)\n",
    "\n",
    "data_ = [nth_rows[i].split() for i in range(len(nth_rows))]\n",
    "\n",
    "df = pd.DataFrame(data_, columns=names)\n",
    "df.to_csv(\"housing_preprocessed.csv\")\n",
    "del df\n",
    "\n",
    "# use the /kaggle/input/boston-house-prices/housing_preprocessed.csv file\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"housing_preprocessed.csv\"\n",
    "# using index\n",
    "df = pd.read_csv(file, usecols = [1, 2, 4], skipfooter=1)\n",
    "df.head()\n",
    "# using column names\n",
    "df = pd.read_csv(file, usecols = [\"CRIM\", \"ZN\", \"CHAS\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'q37'></a>\n",
    "\n",
    "**37. How to get the nrows, ncolumns, datatype, summary stats of each column of a dataframe? Also get the array and list equivalent.**\n",
    "\n",
    "[Go back to the table of contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "# use the \"housing_preprocessed.csv\" file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"housing_preprocessed.csv\", index_col=0 ,skipfooter=1)\n",
    "# number of rows and columns\n",
    "df.shape\n",
    "\n",
    "# each type of column\n",
    "df.dtypes\n",
    "\n",
    "# a more general view of the earlier code\n",
    "df.info()\n",
    "\n",
    "# how many columns under each dtype\n",
    "df.get_dtype_counts()\n",
    "df.dtypes.value_counts()\n",
    "\n",
    "# all the statistics\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'q38'></a>\n",
    "\n",
    "**38. How to extract the row and column number of a particular cell with given criterion?**\n",
    "\n",
    "[Go back to the table of contents](#table_of_contents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "# use the \"housing_preprocessed.csv\" file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution 1\n",
    "df = pd.read_csv(\"housing_preprocessed.csv\", skipfooter=1, index_col=0)\n",
    "# let's get the maximum value\n",
    "max_tax = df[\"TAX\"].max()\n",
    "max_tax\n",
    "\n",
    "# now let's find the column and cell that has the maximum value\n",
    "df[df[\"TAX\"] == max_tax]\n",
    "\n",
    "# solution 2\n",
    "df.loc[df[\"TAX\"] == np.max(df[\"TAX\"]), [\"CRIM\", \"ZN\", \"TAX\"]]\n",
    "\n",
    "# solution 3\n",
    "# get the row and column number\n",
    "row, col = np.where(df.values == np.max(df[\"TAX\"]))\n",
    "for i, j in zip(row, col):\n",
    "    print(i , j)\n",
    "    \n",
    "# Get the value\n",
    "df.iat[row[0], col[0]]\n",
    "df.iloc[row[0], col[0]]\n",
    "\n",
    "# Alternates\n",
    "df.at[row[0], 'TAX']\n",
    "df.get_value(row[0], 'TAX')\n",
    "\n",
    "# The difference between `iat` - `iloc` vs `at` - `loc` is:\n",
    "# `iat` snd `iloc` accepts row and column numbers. \n",
    "# Whereas `at` and `loc` accepts index and column names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'q39'></a>\n",
    "\n",
    "**39. How to rename a specific columns in a dataframe?**\n",
    "\n",
    "[Go back to the table of contents](#table_of_contents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "# Rename the column Type as CarType in df and replace the ‘.’ in column names with ‘_’.\n",
    "cars93 = pd.read_csv(\"../input/cars93/Cars93.csv\", index_col=0)\n",
    "cars93.head()\n",
    "\n",
    "'''\n",
    "Desired Output\n",
    "\n",
    "Index(['Manufacturer', 'Model', 'CarType', 'Min_Price', 'Price', 'Max_Price',\n",
    "        'MPG_city', 'MPG_highway', 'AirBags', 'DriveTrain', 'Cylinders',\n",
    "        'EngineSize', 'Horsepower', 'RPM', 'Rev_per_mile', 'Man_trans_avail',\n",
    "        'Fuel_tank_capacity', 'Passengers', 'Length', 'Wheelbase', 'Width',\n",
    "        'Turn_circle', 'Rear_seat_room', 'Luggage_room', 'Weight', 'Origin',\n",
    "        'Make'],\n",
    "       dtype='object')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 1: in 2 steps\n",
    "# Step1\n",
    "# first let's rename the Type to CarType\n",
    "cars93 = pd.read_csv(\"../input/cars93/Cars93.csv\", index_col=0)\n",
    "cars93.rename(columns={\"Type\":\"CarType\"}, inplace = True)\n",
    "cols = cars93.columns\n",
    "# or\n",
    "df.columns.values[2] = \"CarType\"\n",
    "# Step2\n",
    "# replace the \".\" with \"-\"\n",
    "cols = list(map(lambda x: x.replace(\".\", \"_\"), cols))\n",
    "cars93.columns = cols\n",
    "cars93.head()\n",
    "\n",
    "# Solution 2: working only with lists\n",
    "cars93 = pd.read_csv(\"../input/cars93/Cars93.csv\", index_col=0)\n",
    "cols = cars93.columns\n",
    "cols = list(map(lambda x: x.replace(\".\", \"_\"), cols))\n",
    "cols[cols.index(\"Type\")] = \"CarType\"\n",
    "cars93.columns = cols\n",
    "cars93.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'q40'></a>\n",
    "\n",
    "**40. How to check if a dataframe has any missing values?**\n",
    "\n",
    "[Go back to the table of contents](#table_of_contents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "df = pd.read_csv(\"../input/cars93/Cars93.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 1\n",
    "print(\"Our df has a total of {} null values\".format(df.isnull().sum().sum()))\n",
    "print()\n",
    "\n",
    "# Solution 2\n",
    "df.isnull().values.any()\n",
    "print()\n",
    "\n",
    "# Solution 3\n",
    "# A more detailed one\n",
    "def report_nulls(df):\n",
    "    '''\n",
    "    Show a fast report of the DF.\n",
    "    '''\n",
    "    rows = df.shape[0]\n",
    "    columns = df.shape[1]\n",
    "    null_cols = 0\n",
    "    list_of_nulls_cols = []\n",
    "    for col in list(df.columns):\n",
    "        null_values_rows = df[col].isnull().sum()\n",
    "        null_rows_pcn = round(((null_values_rows)/rows)*100, 2)\n",
    "        col_type = df[col].dtype\n",
    "        if null_values_rows > 0:\n",
    "            print(\"The column {} has {} null values. It is {}% of total rows.\".format(col, null_values_rows, null_rows_pcn))\n",
    "            print(\"The column {} is of type {}.\\n\".format(col, col_type))\n",
    "            null_cols += 1\n",
    "            list_of_nulls_cols.append(col)\n",
    "    null_cols_pcn = round((null_cols/columns)*100, 2)\n",
    "    print(\"The DataFrame has {} columns with null values. It is {}% of total columns.\".format(null_cols, null_cols_pcn))\n",
    "    return list_of_nulls_cols\n",
    "\n",
    "report_nulls(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'q41'></a>\n",
    "\n",
    "**41. How to count the number of missing values in each column?**\n",
    "\n",
    "Count the number of missing values in each column of df. Which column has the maximum number of missing values?\n",
    "\n",
    "[Go back to the table of contents](#table_of_contents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "df = pd.read_csv(\"../input/cars93/Cars93.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 1\n",
    "df_null = pd.DataFrame(df.isnull().sum())\n",
    "df_null[df_null[0] > 0][0].argmax()\n",
    "df_null[df_null[0] > 0][0].idxmax()\n",
    "\n",
    "# Solution 2\n",
    "# find the total number of nulls per column\n",
    "n_missings_each_col = df.apply(lambda x: x.isnull().sum())\n",
    "\n",
    "# find the maximum nulls\n",
    "n_missings_each_col.argmax()\n",
    "n_missings_each_col.idxmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'q42'></a>\n",
    "\n",
    "**42. How to replace missing values of multiple numeric columns with the mean?**\n",
    "\n",
    "Replace missing values in Luggage.room columns with their respective mean.\n",
    "\n",
    "[Go back to the table of contents](#table_of_contents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "df = pd.read_csv(\"../input/cars93/Cars93.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 1\n",
    "beg_null = df.isnull().sum().sum()\n",
    "print(beg_null)\n",
    "# notice that we have filtering the columns  as a list.\n",
    "df[[\"Luggage.room\"]] = df[[\"Luggage.room\"]].apply(lambda x: x.fillna(x.mean()))\n",
    "end_null = df.isnull().sum().sum()\n",
    "print(end_null)\n",
    "\n",
    "print(\"We have got rid of {} null values, filling them with the mean.\".format(beg_null - end_null))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'q43'></a>\n",
    "\n",
    "**43. How to use apply function on existing columns with global variables as additional arguments?**\n",
    "\n",
    "In df, use apply method to replace the missing values in Rear.seat.room with mean Luggage.room with median by passing an argument to the function.\n",
    "\n",
    "[Go back to the table of contents](#table_of_contents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "df = pd.read_csv(\"../input/cars93/Cars93.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "df = pd.read_csv(\"../input/cars93/Cars93.csv\")\n",
    "\n",
    "# Solution 1\n",
    "print(\"We have a total of {} nulls\".format(df.isnull().sum().sum()))\n",
    "\n",
    "d = {'Rear.seat.room': np.nanmean, 'Luggage.room': np.nanmedian}\n",
    "df[['Rear.seat.room', 'Luggage.room']] = df[['Rear.seat.room', 'Luggage.room']].apply(lambda x, d: x.fillna(d[x.name](x)), args=(d, ))\n",
    "\n",
    "print(\"We have a total of {} nulls\".format(df.isnull().sum().sum()))\n",
    "\n",
    "df[\"Rear.seat.room\"].sum()\n",
    "df[\"Luggage.room\"].sum()\n",
    "\n",
    "\n",
    "# Solution 2\n",
    "# impor the df\n",
    "df = pd.read_csv(\"../input/cars93/Cars93.csv\")\n",
    "\n",
    "# check nulls\n",
    "print(\"We have a total of {} nulls\".format(df.isnull().sum().sum()))\n",
    "\n",
    "# define a custom function\n",
    "def num_inputer(x, strategy):\n",
    "    if strategy.lower() == \"mean\":\n",
    "        x = x.fillna(value = np.nanmean(x))\n",
    "    if strategy.lower() == \"median\":\n",
    "        x = x.fillna(value = np.nanmedian(x))\n",
    "    return x\n",
    "\n",
    "# apply the custon function and using args whe can pass the strategy we want\n",
    "df['Rear.seat.room'] = df[['Rear.seat.room']].apply(num_inputer, args = [\"mean\"])\n",
    "df['Luggage.room'] = df[['Luggage.room']].apply(num_inputer, args = [\"median\"])\n",
    "\n",
    "# check for nulls\n",
    "print(\"We have a total of {} nulls\".format(df.isnull().sum().sum()))\n",
    "\n",
    "df[\"Rear.seat.room\"].sum()\n",
    "df[\"Luggage.room\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'q44'></a>\n",
    "\n",
    "**44. How to select a specific column from a dataframe as a dataframe instead of a series?**\n",
    "\n",
    "Get the first column (a) in df as a dataframe (rather than as a Series).\n",
    "\n",
    "[Go back to the table of contents](#table_of_contents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # input\n",
    "df = pd.DataFrame(np.arange(20).reshape(-1, 5), columns=list('abcde'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution\n",
    "# using to_frame()\n",
    "type(df[\"a\"].to_frame())\n",
    "# using pandas DataFrame\n",
    "type(pd.DataFrame(df[\"a\"]))\n",
    "\n",
    "# Other solutions\n",
    "# Solution\n",
    "type(df[['a']])\n",
    "type(df.loc[:, ['a']])\n",
    "type(df.iloc[:, [0]])\n",
    "\n",
    "# This returns a series\n",
    "# Alternately the following returns a Series\n",
    "type(df.a)\n",
    "type(df['a'])\n",
    "type(df.loc[:, 'a'])\n",
    "type(df.iloc[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'q45'></a>\n",
    "\n",
    "**45. How to change the order of columns of a dataframe?**\n",
    "\n",
    "Actually 3 questions.\n",
    "\n",
    "1. In df, interchange columns 'a' and 'c'.\n",
    "\n",
    "2. Create a generic function to interchange two columns, without hardcoding column names.\n",
    "\n",
    "3. Sort the columns in reverse alphabetical order, that is colume 'e' first through column 'a' last.\n",
    "\n",
    "[Go back to the table of contents](#table_of_contents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "df = pd.DataFrame(np.arange(20).reshape(-1, 5), columns=list('abcde'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution to question 1\n",
    "# we pass a list with the custom names BUT THIS DOESN'T change in place\n",
    "df = pd.DataFrame(np.arange(20).reshape(-1, 5), columns=list('abcde'))\n",
    "df[[\"c\", \"b\", \"a\", \"d\", \"e\"]]\n",
    "df\n",
    "\n",
    "# if we reasing that this will work\n",
    "df = df[[\"c\", \"b\", \"a\", \"d\", \"e\"]]\n",
    "df\n",
    "\n",
    "# Solution to question 2\n",
    "def change_cols(df, col1, col2):\n",
    "    df_columns = df.columns.to_list()\n",
    "    index1 = df_columns.index(col1)\n",
    "    index2 = df_columns.index(col2)\n",
    "    # swaping values\n",
    "    df_columns[index1], df_columns[index2] = col1, col2\n",
    "    \n",
    "    return df[df_columns]\n",
    "\n",
    "\n",
    "df = change_cols(df, \"b\", \"e\")\n",
    "df\n",
    "    \n",
    "\n",
    "# Solution to question 3\n",
    "df = pd.DataFrame(np.arange(20).reshape(-1, 5), columns=list('abcde'))\n",
    "col_list = list(df.columns)\n",
    "col_list_reversed = col_list[::-1]\n",
    "col_list\n",
    "col_list_reversed\n",
    "# using the trick from solution 1\n",
    "df = df[col_list_reversed]\n",
    "df\n",
    "\n",
    "\n",
    "print(\"Solution from the website\")\n",
    "print(\"-------------------------\")\n",
    "# Others solution from the website\n",
    "\n",
    "# Input\n",
    "df = pd.DataFrame(np.arange(20).reshape(-1, 5), columns=list('abcde'))\n",
    "\n",
    "# Solution Q1\n",
    "df[list('cbade')]\n",
    "\n",
    "# Solution Q2 - No hard coding\n",
    "def switch_columns(df, col1=None, col2=None):\n",
    "    colnames = df.columns.tolist()\n",
    "    i1, i2 = colnames.index(col1), colnames.index(col2)\n",
    "    colnames[i2], colnames[i1] = colnames[i1], colnames[i2]\n",
    "    return df[colnames]\n",
    "\n",
    "df1 = switch_columns(df, 'a', 'c')\n",
    "\n",
    "# Solution Q3\n",
    "df[sorted(df.columns)]\n",
    "# or\n",
    "df.sort_index(axis=1, ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'q46'></a>\n",
    "\n",
    "**46. How to set the number of rows and columns displayed in the output?**\n",
    "\n",
    "Change the pandas display settings on printing the dataframe df it shows a maximum of 10 rows and 10 columns.\n",
    "\n",
    "\n",
    "[Go back to the table of contents](#table_of_contents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "df = pd.read_csv(\"../input/cars93/Cars93.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use set_option to set the maximun rows and columns to display\n",
    "pd.set_option(\"display.max_columns\",10)\n",
    "pd.set_option(\"display.max_rows\",10)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'q47'></a>\n",
    "\n",
    "**47. How to format or suppress scientific notations in a pandas dataframe?**\n",
    "\n",
    "Suppress scientific notations like ‘e-03’ in df and print upto 4 numbers after decimal.\n",
    "\n",
    "\n",
    "[Go back to the table of contents](#table_of_contents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "df = pd.DataFrame(np.random.random(5)**10, columns=['random'])\n",
    "\n",
    "'''\n",
    "Desired Output\n",
    "#>    random\n",
    "#> 0  0.0035\n",
    "#> 1  0.0000\n",
    "#> 2  0.0747\n",
    "#> 3  0.0000\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Initial DF\")\n",
    "df\n",
    "print(\"Using solution 1\")\n",
    "# Solution 1\n",
    "df.round(4)\n",
    "df\n",
    "pd.reset_option('^display.', silent=True)\n",
    "\n",
    "print(\"Using solution 2\")\n",
    "# Solution 2\n",
    "df.apply(lambda x: '%.4f' %x, axis=1).to_frame()\n",
    "df\n",
    "pd.reset_option('^display.', silent=True)\n",
    "\n",
    "print(\"Using solution 3\")\n",
    "# Solution 3\n",
    "pd.set_option('display.float_format', lambda x: '%.4f'%x)\n",
    "df\n",
    "pd.reset_option('^display.', silent=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'q48'></a>\n",
    "\n",
    "**48. How to format all the values in a dataframe as percentages?**\n",
    "\n",
    "Format the values in column 'random' of df as percentages.\n",
    "\n",
    "\n",
    "[Go back to the table of contents](#table_of_contents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "df = pd.DataFrame(np.random.random(4), columns=['random'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 1\n",
    "# Using style.format we can pass a dictionary to each column and display as we want\n",
    "out = df.style.format({\n",
    "    'random': '{0:.2%}'.format,\n",
    "})\n",
    "out\n",
    "\n",
    "# This applies to all the df\n",
    "pd.options.display.float_format = '{:,.2f}%'.format\n",
    "# to get the % multiply by 100\n",
    "df*100\n",
    "pd.reset_option('^display.', silent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'q49'></a>\n",
    "\n",
    "**49. How to filter every nth row in a dataframe?**\n",
    "\n",
    "From df, filter the 'Manufacturer', 'Model' and 'Type' for every 20th row starting from 1st (row 0).\n",
    "\n",
    "[Go back to the table of contents](#table_of_contents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "df = pd.read_csv(\"../input/cars93/Cars93.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First let's import only the columns we need\n",
    "df = pd.read_csv(\"../input/cars93/Cars93.csv\", usecols=[\"Manufacturer\", \"Model\", \"Type\"])\n",
    "\n",
    "# Solution 1\n",
    "# Using normal python slicing\n",
    "df[::20]\n",
    "\n",
    "df = pd.read_csv(\"../input/cars93/Cars93.csv\", usecols=[\"Manufacturer\", \"Model\", \"Type\"])\n",
    "\n",
    "# Solution 2\n",
    "# Using iloc\n",
    "df.iloc[::20, :][['Manufacturer', 'Model', 'Type']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'q50'></a>\n",
    "\n",
    "**50. How to create a primary key index by combining relevant columns?**\n",
    "\n",
    "In df, Replace NaNs with ‘missing’ in columns 'Manufacturer', 'Model' and 'Type' and create a index as a combination of these three columns and check if the index is a primary key.\n",
    "\n",
    "[Go back to the table of contents](#table_of_contents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "df = pd.read_csv(\"../input/cars93/Cars93.csv\")\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution\n",
    "df = pd.read_csv(\"../input/cars93/Cars93.csv\", usecols=[\"Manufacturer\", \"Model\", \"Type\", \"Min.Price\", \"Max.Price\"])\n",
    "\n",
    "# let's check if we have null\n",
    "df.isnull().sum().sum()\n",
    "df.fillna(\"missing\")\n",
    "# create new index\n",
    "df[\"new_index\"] = df[\"Manufacturer\"] + df[\"Model\"] + df[\"Type\"]\n",
    "# set new index\n",
    "df.set_index(\"new_index\", inplace = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'q51'></a>\n",
    "\n",
    "**51. How to get the row number of the nth largest value in a column?**\n",
    "\n",
    "Find the row position of the 5th largest value of column 'a' in df.\n",
    "\n",
    "[Go back to the table of contents](#table_of_contents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "df = pd.DataFrame(np.random.randint(1, 30, 30).reshape(10,-1), columns=list('abc'))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 1\n",
    "\n",
    "# argsort give the index of the smallest to largest number in an array\n",
    "# arg_sort[0] is the index of the smallest number in df[\"a\"]\n",
    "arg_sort = df[\"a\"].argsort()\n",
    "\n",
    "#arg_sort.to_frame()\n",
    "#arg_sort[0]\n",
    "\n",
    "# now let's sort by arg_sort\n",
    "#df\n",
    "df = df.iloc[arg_sort]\n",
    "df[\"arg_sort\"] = arg_sort\n",
    "df\n",
    "n_largest = 5\n",
    "print(\"The {} largest values in our DF is at row/index {} and the value is {}\".format(n_largest, (df[df[\"arg_sort\"] == (n_largest-1)].index[0]), df[df[\"arg_sort\"] == (n_largest-1)][\"a\"].iloc[0]))\n",
    "\n",
    "# Shorter solution\n",
    "n = 5\n",
    "# select column, argsort, inders (largest to smallest) and select the n largest\n",
    "df['a'].argsort()[::-1][n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'q52'></a>\n",
    "\n",
    "**52. How to find the position of the nth largest value greater than a given value?**\n",
    "\n",
    "In ser, find the position of the 2nd largest value greater than the mean.\n",
    "\n",
    "[Go back to the table of contents](#table_of_contents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "ser = pd.Series(np.random.randint(1, 100, 15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution using argsort and boolean filtering of pandas series\n",
    "# I understood that I wanted the second largest of all values that is greter than the mean\n",
    "# so I sorted\n",
    "#ser\n",
    "sorted_ser = ser[ser.argsort()[::-1]]\n",
    "#sorted_ser\n",
    "sorted_ser[sorted_ser > sorted_ser.mean()].index[1]\n",
    "\n",
    "# If you understood that the 2 value you encounter that is bigger than the mean\n",
    "# This is the correct solution\n",
    "print('ser: ', ser.tolist(), 'mean: ', round(ser.mean()))\n",
    "np.argwhere(ser > ser.mean())[1]\n",
    "\n",
    "# Another solution\n",
    "ser[ser > ser.mean()].index[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<a id = 'q53'></a>\n",
    "\n",
    "**53. How to get the last n rows of a dataframe with row sum > 100?**\n",
    "\n",
    "Get the last two rows of df whose row sum is greater than 100.\n",
    "\n",
    "[Go back to the table of contents](#table_of_contents)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "df = pd.DataFrame(np.random.randint(10, 40, 60).reshape(-1, 4))\n",
    "df1 = df.copy(deep = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 1\n",
    "df[\"sum\"] = df.sum(axis = 1)\n",
    "df\n",
    "\n",
    "print(\"The index of the rows that are greater than 100 are {}\".format((df[df[\"sum\"] > 100].index).to_list()[-2:]))\n",
    "\n",
    "# Solution 2 using numpy\n",
    "rowsums = df1.apply(np.sum, axis=1)\n",
    "\n",
    "# last two rows with row sum greater than 100\n",
    "last_two_rows = df1.iloc[np.where(rowsums > 100)[0][-2:], :]\n",
    "last_two_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<a id = 'q54'></a>\n",
    "\n",
    "**54. How to find and cap outliers from a series or dataframe column?**\n",
    "\n",
    "Replace all values of ser in the lower 5%ile and greater than 95%ile with respective 5th and 95th %ile value.\n",
    "\n",
    "[Go back to the table of contents](#table_of_contents)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "ser = pd.Series(np.logspace(-2, 2, 30))\n",
    "ser1 = ser.copy(deep = True)\n",
    "ser2 = ser.copy(deep = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 1\n",
    "# get the quantiles values\n",
    "quantiles = np.quantile(ser, [0.05, 0.95])\n",
    "ser\n",
    "\n",
    "# filter ser using numpy to know where the values are below or greater than 5% or 95% and replace the values\n",
    "ser.iloc[np.where(ser < quantiles[0])] = quantiles[0]\n",
    "ser.iloc[np.where(ser > quantiles[1])] = quantiles[1]\n",
    "    \n",
    "# or we can just do\n",
    "ser1[ser1 < quantiles[0]] = quantiles[0]\n",
    "ser1[ser1 > quantiles[1]] = quantiles[1]\n",
    "\n",
    "ser1\n",
    "\n",
    "# Solution from the webpage\n",
    "def cap_outliers(ser, low_perc, high_perc):\n",
    "    low, high = ser.quantile([low_perc, high_perc])\n",
    "    print(low_perc, '%ile: ', low, '|', high_perc, '%ile: ', high)\n",
    "    ser[ser < low] = low\n",
    "    ser[ser > high] = high\n",
    "    return(ser)\n",
    "\n",
    "capped_ser = cap_outliers(ser2, .05, .95)\n",
    "ser2\n",
    "capped_ser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<a id = 'q55'></a>\n",
    "\n",
    "**55. How to reshape a dataframe to the largest possible square after removing the negative values?**\n",
    "\n",
    "Reshape df to the largest possible square with negative values removed. Drop the smallest values if need be. \n",
    "The order of the positive numbers in the result should remain the same as the original.\n",
    "\n",
    "[Go back to the table of contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "df = pd.DataFrame(np.random.randint(-20, 50, 100).reshape(10,-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This solution sorts the values.\n",
    "# Not want we want\n",
    "# my_array = np.array(df.values.reshape(-1, 1))\n",
    "# my_array = my_array[my_array > 0]\n",
    "# my_array.shape[0]\n",
    "# lar_square = int(np.floor(my_array.shape[0]**0.5))\n",
    "# arg_sort = np.argsort(my_array)[::-1]\n",
    "# my_array[arg_sort][0:lar_square**2].reshape(lar_square, lar_square)\n",
    "\n",
    "\n",
    "# Correct solution\n",
    "my_array = np.array(df.values.reshape(-1, 1)) # convert to numpy\n",
    "my_array = my_array[my_array > 0] # filter only positive values\n",
    "lar_square = int(np.floor(my_array.shape[0]**0.5)) # find the largest square\n",
    "arg_sort = np.argsort(my_array)[::-1][0:lar_square**2] # eliminate the smallest values that will prevent from converting to a square\n",
    "my_array = np.take(my_array, sorted(arg_sort)).reshape(lar_square, lar_square) # filter the array and reshape back\n",
    "my_array\n",
    "\n",
    "\n",
    "# Solution from the webpage\n",
    "# Step 1: remove negative values from arr\n",
    "arr = df[df > 0].values.flatten()\n",
    "arr_qualified = arr[~np.isnan(arr)]\n",
    "\n",
    "# Step 2: find side-length of largest possible square\n",
    "n = int(np.floor(arr_qualified.shape[0]**.5))\n",
    "\n",
    "# Step 3: Take top n^2 items without changing positions\n",
    "top_indexes = np.argsort(arr_qualified)[::-1]\n",
    "output = np.take(arr_qualified, sorted(top_indexes[:n**2])).reshape(n, -1)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<a id = 'q56'></a>\n",
    "\n",
    "**56. How to swap two rows of a dataframe?**\n",
    "\n",
    "Swap rows 1 and 2 in df.\n",
    "\n",
    "[Go back to the table of contents](#table_of_contents)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "df = pd.DataFrame(np.arange(25).reshape(5, -1))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS SWAPS the columns\n",
    "print(\"Original DataFrame\")\n",
    "df\n",
    "temp_col = df[1].copy(deep = True)\n",
    "df[1], df[2] = df[2], temp_col\n",
    "print(\"Swapped Columns DataFrame\")\n",
    "df\n",
    "\n",
    "# # THIS SWAPS the rows\n",
    "print(\"Original DataFrame\")\n",
    "df\n",
    "temp_row = df.iloc[1].copy(deep = True)\n",
    "df.iloc[1], df.iloc[2] = df.iloc[2], temp_row\n",
    "print(\"Swapped Rows DataFrame\")\n",
    "df\n",
    "\n",
    "# Solution from the webpage\n",
    "def swap_rows(df, i1, i2):\n",
    "    a, b = df.iloc[i1, :].copy(), df.iloc[i2, :].copy()\n",
    "    df.iloc[i1, :], df.iloc[i2, :] = b, a\n",
    "    return df\n",
    "\n",
    "print(swap_rows(df, 1, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<a id = 'q57'></a>\n",
    "\n",
    "**57. How to reverse the rows of a dataframe?**\n",
    "\n",
    "Reverse all the rows of dataframe df.\n",
    "\n",
    "[Go back to the table of contents](#table_of_contents)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "df = pd.DataFrame(np.arange(25).reshape(5, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 1\n",
    "df\n",
    "df.iloc[df.index.to_list()[::-1]]\n",
    "\n",
    "# Solutions from the webpage\n",
    "# Solution 2\n",
    "df.iloc[::-1, :]\n",
    "\n",
    "# Solution 3\n",
    "print(df.loc[df.index[::-1], :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<a id = 'q58'></a>\n",
    "\n",
    "**58. How to create one-hot encodings of a categorical variable (dummy variables)?**\n",
    "\n",
    "Get one-hot encodings for column 'a' in the dataframe df and append it as columns.\n",
    "\n",
    "[Go back to the table of contents](#table_of_contents)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "df = pd.DataFrame(np.arange(25).reshape(5,-1), columns=list('abcde'))\n",
    "\n",
    "'''\n",
    "Desired Output\n",
    "\n",
    "   0  5  10  15  20   b   c   d   e\n",
    "0  1  0   0   0   0   1   2   3   4\n",
    "1  0  1   0   0   0   6   7   8   9\n",
    "2  0  0   1   0   0  11  12  13  14\n",
    "3  0  0   0   1   0  16  17  18  19\n",
    "4  0  0   0   0   1  21  22  23  24\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using pd.get_dummies\n",
    "dummies = pd.get_dummies(df[\"a\"])\n",
    "df = pd.concat([dummies, df], axis = 1)\n",
    "df\n",
    "\n",
    "# Solution from the webpage\n",
    "# in one line\n",
    "df_onehot = pd.concat([pd.get_dummies(df['a']), df[list('bcde')]], axis=1)\n",
    "df_onehot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<a id = 'q59'></a>\n",
    "\n",
    "**59. Which column contains the highest number of row-wise maximum values?**\n",
    "\n",
    "Obtain the column name with the highest number of row-wise maximum’s in df.\n",
    "\n",
    "[Go back to the table of contents](#table_of_contents)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "df = pd.DataFrame(np.random.randint(1,100, 40).reshape(10, -1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 1\n",
    "def get_col(df):\n",
    "    columns = list(df.columns)\n",
    "    df[\"col_index_with_max\"] = \"\"\n",
    "    for i in range(len(df)):\n",
    "        row_values = list(df.iloc[i, :-1].values)\n",
    "        max_value = np.max(row_values)\n",
    "        col_index = row_values.index(max_value)\n",
    "        df[\"col_index_with_max\"].iloc[i] = col_index\n",
    "\n",
    "get_col(df)\n",
    "\n",
    "df\n",
    "print(\"The col with maximum amont of maximun per row if {} with a total of {} maximus\".format(df.groupby(\"col_index_with_max\").size()[::-1].index[0], \\\n",
    "                                                                                              df.groupby(\"col_index_with_max\").size()[::-1].values[0]))\n",
    "\n",
    "# Solution 2\n",
    "# Another much more elegant solution from the webpage\n",
    "print('Column with highest row maxes: ', df.apply(np.argmax, axis=1).value_counts().index[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<a id = 'q60'></a>\n",
    "\n",
    "**60. How to create a new column that contains the row number of nearest column by euclidean distance?**\n",
    "\n",
    "Create a new column such that, each row contains the row number of nearest row-record by euclidean distance.\n",
    "\n",
    "[Go back to the table of contents](#table_of_contents)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "df = pd.DataFrame(np.random.randint(1,100, 40).reshape(10, -1), columns=list('pqrs'), index=list('abcdefghij'))\n",
    "\n",
    "'''\n",
    "Desired Output\n",
    "\n",
    "df\n",
    "#    p   q   r   s nearest_row   dist\n",
    "# a  57  77  13  62           i  116.0\n",
    "# b  68   5  92  24           a  114.0\n",
    "# c  74  40  18  37           i   91.0\n",
    "# d  80  17  39  60           i   89.0\n",
    "# e  93  48  85  33           i   92.0\n",
    "# f  69  55   8  11           g  100.0\n",
    "# g  39  23  88  53           f  100.0\n",
    "# h  63  28  25  61           i   88.0\n",
    "# i  18   4  73   7           a  116.0\n",
    "# j  79  12  45  34           a   81.0\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "# Solution 1\n",
    "# input\n",
    "df = pd.DataFrame(np.random.randint(1,100, 40).reshape(10, -1), columns=list('pqrs'), index=list('abcdefghij'))\n",
    "\n",
    "# place holders\n",
    "corr_list = []\n",
    "index_list = []\n",
    "\n",
    "# temporary var\n",
    "max_corr = 0\n",
    "current_index = \"\"\n",
    "\n",
    "# nested loop to calculate\n",
    "for i in range(len(df)):\n",
    "    for j in range(len(df)):\n",
    "        if i == j:\n",
    "            pass\n",
    "        else:\n",
    "            # distance\n",
    "            curr_corr = sum((df.iloc[i] - df.iloc[j])**2)**.5\n",
    "            # correlation\n",
    "            #curr_corr = df.iloc[i].corr(df.iloc[j])\n",
    "            if curr_corr >= max_corr:\n",
    "                max_corr = curr_corr\n",
    "                current_index = list(df.index)[j]\n",
    "                \n",
    "    corr_list.append(max_corr)\n",
    "    index_list.append(current_index)\n",
    "    \n",
    "    max_corr = 0\n",
    "    current_index = \"\"\n",
    "    \n",
    "df[\"nearest_row\"] = index_list\n",
    "df[\"dist\"] = corr_list\n",
    "df\n",
    "df.drop([\"nearest_row\", \"dist\"], axis = 1, inplace = True)\n",
    "\n",
    "#######################################################################################################################################\n",
    "\n",
    "# Solution from the webpage\n",
    "# init outputs\n",
    "nearest_rows = []\n",
    "nearest_distance = []\n",
    "\n",
    "# iterate rows.\n",
    "for i, row in df.iterrows():\n",
    "    curr = row\n",
    "    rest = df.drop(i)\n",
    "    e_dists = {}  # init dict to store euclidean dists for current row.\n",
    "    # iterate rest of rows for current row\n",
    "    for j, contestant in rest.iterrows():\n",
    "        # compute euclidean dist and update e_dists\n",
    "        e_dists.update({j: round(np.linalg.norm(curr.values - contestant.values))})\n",
    "    # update nearest row to current row and the distance value\n",
    "    nearest_rows.append(max(e_dists, key=e_dists.get))\n",
    "    nearest_distance.append(max(e_dists.values()))\n",
    "\n",
    "df['nearest_row'] = nearest_rows\n",
    "df['dist'] = nearest_distance\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<a id = 'q61'></a>\n",
    "\n",
    "**61. How to know the maximum possible correlation value of each column against other columns?**\n",
    "\n",
    "For each column get the maximum possible correlation with other columns (only 1 value)\n",
    "\n",
    "[Go back to the table of contents](#table_of_contents)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "df = pd.DataFrame(np.random.randint(1,100, 80).reshape(8, -1), columns=list('pqrstuvwxy'), index=list('abcdefgh'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# calculate the correlation, returns a matrix \n",
    "df_corr = np.abs(df.corr())\n",
    "# sorted -2 because it goes from min to max\n",
    "# max = 1 because it's correlation againts each other\n",
    "# so we pick -2\n",
    "max_corr = df_corr.apply(lambda x: sorted(x)[-2], axis = 0)\n",
    "max_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<a id = 'q62'></a>\n",
    "\n",
    "**62. How to create a column containing the minimum by maximum of each row?**\n",
    "\n",
    "Compute the minimum-by-maximum for every row of df.\n",
    "\n",
    "[Go back to the table of contents](#table_of_contents)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "df = pd.DataFrame(np.random.randint(1,100, 80).reshape(8, -1))\n",
    "df1 = df.copy(deep = True)\n",
    "df2 = df.copy(deep = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 1\n",
    "df[\"min_by_max\"] = (df.apply(min, axis = 1)/df.apply(max, axis = 1))\n",
    "df\n",
    "\n",
    "# Other solution from the webpage\n",
    "# Solution 2\n",
    "min_by_max = df1.apply(lambda x: np.min(x)/np.max(x), axis=1)\n",
    "min_by_max\n",
    "# Solution 3\n",
    "min_by_max = np.min(df2, axis=1)/np.max(df2, axis=1)\n",
    "min_by_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<a id = 'q63'></a>\n",
    "\n",
    "**63. How to create a column that contains the penultimate value in each row?**\n",
    "\n",
    "Create a new column 'penultimate' which has the second largest value of each row of df.\n",
    "\n",
    "[Go back to the table of contents](#table_of_contents)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "df = pd.DataFrame(np.random.randint(1,100, 80).reshape(8, -1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using lambda and numpy partition\n",
    "df[\"penultimate\"] = df.apply(lambda x: np.partition(x, -2)[-2], axis = 1)\n",
    "df\n",
    "df.drop(\"penultimate\", inplace = True, axis = 1)\n",
    "\n",
    "# Using lambda and python lists\n",
    "df[\"penultimate\"] = df.apply(lambda x: sorted(list(x))[-2], axis = 1)\n",
    "df\n",
    "df.drop(\"penultimate\", inplace = True, axis = 1)\n",
    "\n",
    "# Solution from the webpage\n",
    "out = df.apply(lambda x: x.sort_values().unique()[-2], axis=1)\n",
    "df['penultimate'] = out\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<a id = 'q64'></a>\n",
    "\n",
    "**64. How to normalize all columns in a dataframe?**\n",
    "\n",
    "1. Normalize all columns of df by subtracting the column mean and divide by standard deviation.\n",
    "\n",
    "2. Range all columns of df such that the minimum value in each column is 0 and max is 1.\n",
    "\n",
    "**Don’t use external packages like sklearn**\n",
    "\n",
    "[Go back to the table of contents](#table_of_contents)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "df = pd.DataFrame(np.random.randint(1,100, 80).reshape(8, -1))\n",
    "df1 = df.copy(deep = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First normalization: mean and std    \n",
    "df = df.apply(lambda x: ((x-np.mean(x))/np.std(x)), axis = 0)\n",
    "df\n",
    "\n",
    "# min max\n",
    "df1 = df1.apply(lambda x: ((x.max() - x)/(x.max() - x.min())).round(2))\n",
    "df1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<a id = 'q65'></a>\n",
    "\n",
    "**65. How to compute the correlation of each row with the suceeding row?**\n",
    "\n",
    "Compute the correlation of each row of df with its succeeding row.\n",
    "\n",
    "[Go back to the table of contents](#table_of_contents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "df = pd.DataFrame(np.random.randint(1,100, 80).reshape(8, -1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"corr\"] = 0\n",
    "for i in range(len(df)-1):\n",
    "    \n",
    "    values1 = df.iloc[i, :-1].astype('float64')\n",
    "    values2 = df.iloc[i+1, :-1].astype('float64')\n",
    "    corr = values1.corr(values2)\n",
    "    df[\"corr\"].iloc[i] = corr\n",
    "df\n",
    "df.drop(\"corr\", inplace = True, axis = 1)\n",
    "\n",
    "# Solution from the webpage\n",
    "# using list comprehension\n",
    "[df.iloc[i].corr(df.iloc[i+1]).round(2) for i in range(df.shape[0])[:-1]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<a id = 'q66'></a>\n",
    "\n",
    "**66. How to replace both the diagonals of dataframe with 0?**\n",
    "\n",
    "Replace both values in both diagonals of df with 0.\n",
    "\n",
    "[Go back to the table of contents](#table_of_contents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "df = pd.DataFrame(np.random.randint(1,100, 100).reshape(10, -1))\n",
    "df1 = df.copy(deep = True)\n",
    "\n",
    "'''\n",
    "Desired Output (might change because of randomness)\n",
    "\n",
    "#     0   1   2   3   4   5   6   7   8   9\n",
    "# 0   0  46  26  44  11  62  18  70  68   0\n",
    "# 1  87   0  52  50  81  43  83  39   0  59\n",
    "# 2  47  76   0  77  73   2   2   0  14  26\n",
    "# 3  64  18  74   0  16  37   0   8  66  39\n",
    "# 4  10  18  39  98   0   0  32   6   3  29\n",
    "# 5  29  91  27  86   0   0  28  31  97  10\n",
    "# 6  37  71  70   0   4  72   0  89  12  97\n",
    "# 7  65  22   0  75  17  10  43   0  12  77\n",
    "# 8  47   0  96  55  17  83  61  85   0  86\n",
    "# 9   0  80  28  45  77  12  67  80   7   0\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "df = pd.DataFrame(np.random.randint(1,100, 100).reshape(10, -1))\n",
    "df1 = df.copy(deep = True)\n",
    "\n",
    "# Using nested loops\n",
    "print(\"Original DF\")\n",
    "df\n",
    "for i in range(len(df)):\n",
    "    for j in range(len(df)):\n",
    "        if i == j:\n",
    "            df.iloc[i ,j] = 0\n",
    "            # Inverse the matrix so that we can replace the other diagonal\n",
    "            df[::-1].iloc[i, j] = 0\n",
    "\n",
    "print(\"DF from the solution 1\")\n",
    "df\n",
    "\n",
    "# Solution from the webpage\n",
    "# Solution\n",
    "for i in range(df1.shape[0]):\n",
    "    df1.iat[i, i] = 0\n",
    "    df1.iat[df1.shape[0]-i-1, i] = 0\n",
    "    \n",
    "print(\"DF from the solution 2\")\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'q67'></a>\n",
    "\n",
    "**67. How to get the particular group of a groupby dataframe by key?**\n",
    "\n",
    "This is a question related to understanding of grouped dataframe. From df_grouped, get the group belonging to 'apple' as a dataframe.\n",
    "\n",
    "[Go back to the table of contents](#table_of_contents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "df = pd.DataFrame({'col1': ['apple', 'banana', 'orange'] * 3,\n",
    "                   'col2': np.random.rand(9),\n",
    "                   'col3': np.random.randint(0, 15, 9)})\n",
    "\n",
    "df_grouped = df.groupby(['col1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 1\n",
    "pd.DataFrame(df_grouped)\n",
    "df_grouped.groups[\"apple\"]\n",
    "df_grouped.get_group(\"apple\")\n",
    "\n",
    "# Solution 2\n",
    "for i, dff in df_grouped:\n",
    "    if i == 'apple':\n",
    "        print(dff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'q68'></a>\n",
    "\n",
    "**68. How to get the n’th largest value of a column when grouped by another column?**\n",
    "\n",
    "In df, find the second largest value of 'rating' for 'banana'\n",
    "\n",
    "[Go back to the table of contents](#table_of_contents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "df = pd.DataFrame({'fruit': ['apple', 'banana', 'orange'] * 3,\n",
    "                   'rating': np.random.rand(9),\n",
    "                   'price': np.random.randint(0, 15, 9)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 1\n",
    "grouped_by = df[\"rating\"].groupby(df[\"fruit\"])\n",
    "grouped_by.get_group(\"banana\")\n",
    "list(grouped_by.get_group(\"banana\"))[1]\n",
    "\n",
    "# Solution from the webpage\n",
    "df_grpd = df['rating'].groupby(df.fruit)\n",
    "df_grpd.get_group('banana')\n",
    "df_grpd.get_group('banana').sort_values().iloc[-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'q69'></a>\n",
    "\n",
    "**69. How to compute grouped mean on pandas dataframe and keep the grouped column as another column (not index)?**\n",
    "\n",
    "In df, Compute the mean price of every fruit, while keeping the fruit as another column instead of an index.\n",
    "\n",
    "[Go back to the table of contents](#table_of_contents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "df = pd.DataFrame({'fruit': ['apple', 'banana', 'orange'] * 3,\n",
    "                   'rating': np.random.rand(9),\n",
    "                   'price': np.random.randint(0, 15, 9)})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using pandas pivot table\n",
    "df_grouped = pd.pivot_table(df[[\"fruit\", \"price\"]], index = [\"fruit\"], aggfunc = np.mean ).reset_index()\n",
    "df_grouped\n",
    "\n",
    "# using groupby\n",
    "out = df.groupby('fruit', as_index=False)['price'].mean()\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'q70'></a>\n",
    "\n",
    "**70. How to join two dataframes by 2 columns so they have only the common rows?**\n",
    "\n",
    "Join dataframes df1 and df2 by ‘fruit-pazham’ and ‘weight-kilo’.\n",
    "\n",
    "[Go back to the table of contents](#table_of_contents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "df1 = pd.DataFrame({'fruit': ['apple', 'banana', 'orange'] * 3,\n",
    "                    'weight': ['high', 'medium', 'low'] * 3,\n",
    "                    'price': np.random.randint(0, 15, 9)})\n",
    "\n",
    "df2 = pd.DataFrame({'pazham': ['apple', 'orange', 'pine'] * 2,\n",
    "                    'kilo': ['high', 'low'] * 3,\n",
    "                    'price': np.random.randint(0, 15, 6)})\n",
    "df1\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 1\n",
    "# using pandas merge\n",
    "merge_df = pd.merge(df1, df2, left_on=[\"fruit\", \"weight\"], right_on=[\"pazham\", \"kilo\"])\n",
    "merge_df\n",
    "\n",
    "\n",
    "# Solution from the webpage\n",
    "pd.merge(df1, df2, how='inner', left_on=['fruit', 'weight'], right_on=['pazham', 'kilo'], suffixes=['_left', '_right'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'q71'></a>\n",
    "\n",
    "**71. How to remove rows from a dataframe that are present in another dataframe?**\n",
    "\n",
    "From df1, remove the rows that are present in df2. All three columns must be the same.\n",
    "\n",
    "[Go back to the table of contents](#table_of_contents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "df1 = pd.DataFrame({'fruit': ['apple', 'banana', 'orange'] * 3,\n",
    "                    'weight': ['high', 'medium', 'low'] * 3,\n",
    "                    'price': np.random.randint(0, 10, 9)})\n",
    "\n",
    "df2 = pd.DataFrame({'pazham': ['apple', 'orange', 'pine'] * 2,\n",
    "                    'kilo': ['high', 'low'] * 3,\n",
    "                    'price': np.random.randint(0, 10, 6)})\n",
    "\n",
    "df1\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We might use pandas merge\n",
    "#df1.merge(df2, how = \"inner\", left_on = [\"fruit\", \"weight\", \"price\"], right_on = [\"pazham\", \"kilo\", \"price\"])\n",
    "\n",
    "df1[\"concat\"] = df1[\"fruit\"].astype(str) + df1[\"weight\"].astype(str) + df1[\"price\"].astype(str)\n",
    "#df1\n",
    "\n",
    "df2[\"concat\"] = df2[\"pazham\"].astype(str) + df2[\"kilo\"].astype(str) + df2[\"price\"].astype(str)\n",
    "#df2\n",
    "\n",
    "df1 = df1[~df1[\"concat\"].isin(df2[\"concat\"])]\n",
    "df1.drop(\"concat\", inplace = True, axis = 1)\n",
    "df1\n",
    "\n",
    "# Solution from the webpage, IMHO it's incorrect\n",
    "#df1[~df1.isin(df2).all(1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'q72'></a>\n",
    "\n",
    "**72. How to get the positions where values of two columns match?**\n",
    "\n",
    "Find the index where col fruit1 and fruit2 match\n",
    "\n",
    "[Go back to the table of contents](#table_of_contents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "df = pd.DataFrame({'fruit1': np.random.choice(['apple', 'orange', 'banana'], 10),\n",
    "                    'fruit2': np.random.choice(['apple', 'orange', 'banana'], 10)})\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution\n",
    "np.where(df.fruit1 == df.fruit2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'q73'></a>\n",
    "\n",
    "**73. How to create lags and leads of a column in a dataframe?**\n",
    "\n",
    "Create two new columns in df, one of which is a lag1 (shift column a down by 1 row) of column ‘a’ and the other is a lead1 (shift column b up by 1 row).\n",
    "\n",
    "[Go back to the table of contents](#table_of_contents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "df = pd.DataFrame(np.random.randint(1, 100, 20).reshape(-1, 4), columns = list('abcd'))\n",
    "df\n",
    "\n",
    "'''\n",
    "Desired Output\n",
    "\n",
    "    a   b   c   d  a_lag1  b_lead1\n",
    "0  66  34  76  47     NaN     86.0\n",
    "1  20  86  10  81    66.0     73.0\n",
    "2  75  73  51  28    20.0      1.0\n",
    "3   1   1   9  83    75.0     47.0\n",
    "4  30  47  67   4     1.0      NaN\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"lag1\"] = df[\"a\"].shift(1)\n",
    "df[\"lead1\"] = df[\"b\"].shift(-1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'q74'></a>\n",
    "\n",
    "**74. How to get the frequency of unique values in the entire dataframe?**\n",
    "\n",
    "Get the frequency of unique values in the entire dataframe df.\n",
    "\n",
    "[Go back to the table of contents](#table_of_contents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "df = pd.DataFrame(np.random.randint(1, 10, 20).reshape(-1, 4), columns = list('abcd'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution\n",
    "pd.value_counts(df.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'q75'></a>\n",
    "\n",
    "**75. How to split a text column into two separate columns?**\n",
    "\n",
    "Split the string column in df to form a dataframe with 3 columns as shown.\n",
    "\n",
    "[Go back to the table of contents](#table_of_contents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "df = pd.DataFrame([\"STD, City    State\",\n",
    "\"33, Kolkata    West Bengal\",\n",
    "\"44, Chennai    Tamil Nadu\",\n",
    "\"40, Hyderabad    Telengana\",\n",
    "\"80, Bangalore    Karnataka\"], columns=['row'])\n",
    "\n",
    "df\n",
    "\n",
    "'''\n",
    "Desired Output\n",
    "\n",
    "0 STD        City        State\n",
    "1  33     Kolkata  West Bengal\n",
    "2  44     Chennai   Tamil Nadu\n",
    "3  40   Hyderabad    Telengana\n",
    "4  80   Bangalore    Karnataka\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we do \" \".join(x.split()) to replace multiple spaces to 1 space\n",
    "# we do split(None, 2, ) to split a string on the second space ()this way we have West Bengal together\n",
    "df[\"re\"] = df[\"row\"].apply(lambda x: \" \".join(x.split()).split(None, 2, ))\n",
    "\n",
    "new_header = df[\"re\"][0]\n",
    "values = df[\"re\"][1:]\n",
    "\n",
    "# our values is a series of lists, we have to do some list comprehension no extract the values\n",
    "d = {new_header[0]:[int(values.iloc[i][0].replace(\",\", \"\")) for i in range(len(values))], \\\n",
    "     new_header[1]:[values.iloc[i][1].replace(\",\", \"\") for i in range(len(values))], \\\n",
    "     new_header[2]:[values.iloc[i][2].replace(\",\", \"\") for i in range(len(values))]}\n",
    "\n",
    "# create a pandas DF from a dict\n",
    "new_df = pd.DataFrame(d)\n",
    "new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The End\n",
    "# Thank you very much!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
